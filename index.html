<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>Emergence of Abstract State Representations in Embodied Sequence Modeling</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Creative and Descriptive Paper Title." />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<center>
		<br>
		<span style="font-size:36px "><b>Emergence of Abstract State Representations <br> in Embodied Sequence Modeling</b></span>
		<br>
		<br>

		<table align=center width=600px>
			<table align=center width=800px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://tttyuntian.github.io/">Tian Yun</a>*</span>
							<br>
							<span style="font-size:16px">Brown University</span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://zilaiz.github.io/">Zilai Zeng</a>*</span>
							<br>
							<span style="font-size:16px">Brown University</span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://kunhanda.github.io/">Kunal Handa</a></span>
							<br>
							<span style="font-size:16px">Brown University</span>
						</center>
					</td>
				</tr>
			</table>
			<br>
			<table align=center width=800px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://scholar.google.com/citations?user=1JtHXbAAAAAJ&hl=en">Ashish V. Thapliyal</a></span>
							<br>
							<span style="font-size:16px">Google Research</span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://scholar.google.com/citations?user=qCdLtIoAAAAJ&hl=en">Bo Pang</a></span>
							<br>
							<span style="font-size:16px">Google Research</span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://scholar.google.com/citations?user=sFyrSa8AAAAJ&hl=en">Ellie Pavlick</a></span>
							<br>
							<span style="font-size:16px">Brown University</span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://chensun.me/index.html">Chen Sun</a></span>
							<br>
							<span style="font-size:16px">Brown University</span>
						</center>
					</td>
				</tr>
			</table>
			<br>
			<table align=center width=300px>
				<tr>
					<td align=center width=120px>
						<center>
							<div class="buttons" style="margin-bottom: 8px;"><a class="btn btn-primary" role="button" href="https://arxiv.org/abs/2311.02171">[Paper]</a></div>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<div class="buttons" style="margin-bottom: 8px;"><a class="btn btn-primary" role="button" href="https://github.com/brown-palm/abstract-state-seqmodel">[Code]</a></div>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Reinforcement learning via sequence modeling aims to mimic the success of language models, where actions taken by an embodied agent are modeled as tokens to predict. Despite their promising performance, it remains unclear if embodied sequence modeling leads to the emergence of internal representations that represent the environmental state information. A model that lacks abstract state representations would be liable to make decisions based on surface statistics which fail to generalize. We take the BabyAI environment, a grid world in which language-conditioned navigation tasks are performed, and build a sequence modeling Transformer, which takes a language instruction, a sequence of actions, and environmental observations as its inputs. In order to investigate the emergence of abstract state representations, we design a "blindfolded" navigation task, where only the initial environmental layout, the language instruction, and the action sequence to complete the task are available for training. 
				<br><br>
				Our probing results show that intermediate environmental layouts can be reasonably reconstructed from the internal activations of a trained model, and that language instructions play a role on the construction accuracy. Our results suggest that many key features of state representations can emerge via embodied sequence modeling, supporting an optimistic outlook for applications of sequence modeling objectives to more complex embodied decision-making domains.
			</td>
		</tr>
	</table>

	<br><hr>

	<!-- <hr>
	<center><h1>Video Presentation</h1></center>
	<p align="center">
		<iframe width="660" height="395" src="https://www.youtube.com/embed/qerql58NeeE" frameborder="0" allowfullscreen align="center"></iframe>
	</p>
	<hr> -->

	<center><h1>BabyAI</h1></center>

	<table align=center width=400px>
		<center><tr>
			<td align=center width=650px>
				<center>
					<img class="round" style="width:650px" src="./resources/babyai_illustration.png"/>
				</center>
			</td>
		</tr></center>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					<br> We use the <a href="https://minigrid.farama.org/environments/babyai/index.html">BabyAI</a> environment as a testbed to investigate whether embodied sequence modeling leads to the emergence of abstract internal representations of the environment. The goal in this environment is to control an agent to navigate and interact in an <em>N</em> by <em>N</em> grid to follow the given language instructions (e.g., "go to the yellow key").

					<br><br>
					Above is a demonstration of a language-conditioned navigation task in BabyAI <em>GoToLocal</em> level where an agent (i.e., red triangle) needs to navigate to the target objects specified in the given instructions. This is an example trajectory where the agent achieves the goal of "go to the grey key": 
					<ol type="A">
						<li>The board is randomly initialized with the agent and 8 objects.</li>
						<li>The agent navigates in the environment to try to approach the target object.</li>
						<li>The agent keeps navigating until it reaches the target object.</li>
					</ol>
				</td>
			</tr>
		</center>
	</table>

	<br><hr>

	<center><h1>Methods</h1></center>

	<table align=center width=400px>
		<tr>
			<td align=center width=1000px>
				<center>
					<td><img class="round" style="width:600px" src="./resources/sequece_model_architecture.png"/></td>
					<td><img class="round" style="width:400px" src="./resources/probing_pipeline.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					We build our embodied sequence modeling framework with a Transformer-based architecture, in which we can process heterogeneous data (e.g. natural language instructions, states and actions) as sequences and autoregressively model the state-action trajectories with causal attention masks.
					<br><br>
					Once we have models trained to perform a language-conditioned navigation task, we train simple classifiers as probes to explore whether the internal activations of a trained model contain representations of abstract environmental states (e.g., current board layouts). If the trained probes can accurately reconstruct the current state when it is not explicitly given to the model, it suggests that abstract state representations can emerge during model's pretraining. 
					<br><br>
					We introduce two sequence modeling setups in BabyAI, namely the <b>Regular setup</b> and the <b>Blindfolded setup</b>. 
					<ul>
						<li><b>Regular Setup</b>: The objective is to predict next actions based on all the information at the current and the previous steps provided explicitly including intermediate states which are computed using the BabyAI environment.</li>
						<li><b>Blindfolded Setup</b>: The objective is to predict next actions based on the language instruction, prior actions, and only the initial state. By comparing state reconstruction task and task completion performance of this setup against the regular setup, we hope to gain insights into whether these sequence models are able to internally reconstruct the intermediate states implicitly in order to determine the right next actions to take. </li>
					</ul>
				</td>
			</tr>
		</center>
	</table>
	
	<hr>

	<center><h1>Results</h1></center>

	<table align=center width=850px>
		<center>
			<tr>
				<td>
					We train a sequence model which simulates the regular setup and blindfolded setup of sequence modeling in BabyAI, named as <em>Complete-State Model</em> and <em>Missing-State Model</em> respectively. 
					<br>
					<em>Randomly initialized baseline</em> is a probe trained on a sequence model with random weights.
					<br>
					<em>Initial state baseline</em> to always predict the initial state, without considering the actions taken by the agent. 
				</td>
			</tr>
		</center>
	</table>
	<br>

	<table align=center width=850px>
		<center>
			<tr>
				<td>
					<b>1. Role of Intermediate State Observations in the Emergence of State Representations</b>
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=1000px>
				<center>
					<td><img class="round" style="width:600px" src="./resources/gotolocal_roles_of_states.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					We perform probing on the internal activations of a pretrained Complete-State model and a pretrained Missing-State model.
					For Complete-State model, while the current state is explicitly fed to the model as part of its input, the poor performance of the randomly initialized weights confirms that this information is not trivially preserved in its internal activations - the model needs to be properly pretrained for that to happen. For Missing-State model, even though the current states are not explicitly given, they can be reconstructed reasonably well from the model's internal representations.
				</td>
			</tr>
		</center>
	</table>
	
	<br>

	<table align=center width=850px>
		<center>
			<tr>
				<td>
					<b>2. Role of Language Instructions in the Emergence of State Representations</b>
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=1000px>
				<center>
					<td><img class="round" style="width:600px" src="./resources/gotolocal_roles_of_instructions.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					To study how language instructions impact the emergence of internal representations of states, we pretrain a Complete-State model and a Missing-State model without passing in language instructions. 
					When the language instruction is absent during pretraining, the models struggle to recover state information as accurately as the models trained with language instructions, which reflects that language instructions play an important role in the emergence of internal state representations.
				</td>
			</tr>
		</center>
	</table>
	
	<br>
	
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					<b>3. Blindfolded Navigation Performance</b>
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=1000px>
				<center>
					<td><img class="round" style="width:600px" src="./resources/gotolocal_navigation_performance.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					We further explore the practical implications of the emergence of internal state representations by evaluating pretrained Complete- and Missing-State models on GoToLocal. 
					We observe that Missing-State model performs competitively against Complete-State model, even though Missing-State model only has access to the non-initial/last states during its training. This aligns with our expectation that a model which learns internal representations of states can utilize such representations to predict next actions. 
				</td>
			</tr>
		</center>
	</table>
	
	<br><hr>

	<table align=center width=650px>
		<center><h1>Paper and BibTex</h1></center>
		<tr>
			<td><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></td>
			<td><span style="font-size:14pt">Tian Yun*, Zilai Zeng*, Kunal Handa, Ashish V. Thapliyal, Bo Pang, Ellie Pavlick, Chen Sun.<br>
				<b>Emergence of Abstract State Representations in Embodied Sequence Modeling</b><br>
				In EMNLP 2023.<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br><br>

	<table align=center width=850px>
		<center>
			<tr>
				<td style="background-color:#e1e1e1">
					<pre><code>
  @inproceedings{yun2023emergence,
	title={Emergence of Abstract State Representations in Embodied Sequence Modeling},
	author={Tian Yun and Zilai Zeng and Kunal Handa and Ashish V Thapliyal and Bo Pang and Ellie Pavlick and Chen Sun},
	booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing},
	year={2023}
  }
					</code></pre>
				</td>
			</tr>
		</center>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					We would like to thank the anonymous reviewers for their detailed and constructive comments. We are very grateful to Xi Chen, Sebastian Goodman, and Radu Soricut for useful discussions . We appreciate Kenneth Li for helpful feedback on probing experiments and further conversation about potentials of the project. We thank Haotian Fu, Apoorv Khandelwal, Michael Lepori, Calvin Luo, and Jack Merullo for the help on the project. Part of the work was done while Tian Yun was a student researcher at Google Research. This project is in part supported by Samsung Advanced Institute of Technology, and a Richard B. Salomon Faculty Research Award for C.S.

					<br><br>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

